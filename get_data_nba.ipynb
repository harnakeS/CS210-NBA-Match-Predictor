{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da371ade-32af-419d-81c1-3ec022b87694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeout\n",
    "\n",
    "# Define the range of seasons to process\n",
    "YEARS = [yr for yr in range(2010, 2024)]\n",
    "\n",
    "# Set up directory paths for data storage\n",
    "BASE_DATA_DIR = \"data\"\n",
    "STANDINGS_PATH = os.path.join(BASE_DATA_DIR, \"standings\")\n",
    "SCORES_PATH = os.path.join(BASE_DATA_DIR, \"scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad2baf5-1c3d-4ccf-955e-ee4d7bb00069",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_html(page_url, css_selector, delay_between_retries=5, max_attempts=3):\n",
    "    \"\"\"\n",
    "    Attempt to load the HTML content from a given URL using Playwright.\n",
    "    Retries multiple times in case of timeouts, increasing the delay each attempt.\n",
    "    \"\"\"\n",
    "    page_html = None\n",
    "    for attempt in range(1, max_attempts + 1):\n",
    "        time.sleep(delay_between_retries * attempt)\n",
    "        try:\n",
    "            async with async_playwright() as playwright:\n",
    "                browser = await playwright.firefox.launch()\n",
    "                page = await browser.new_page()\n",
    "                await page.goto(page_url)\n",
    "                print(await page.title())\n",
    "                page_html = await page.inner_html(css_selector)\n",
    "        except PlaywrightTimeout:\n",
    "            print(f\"Encountered a timeout at: {page_url}\")\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return page_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13821605-3198-48d2-bacb-036bba9bf6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def retrieve_season_data(season_year):\n",
    "    \"\"\"\n",
    "    For a given season, retrieve the main schedule page and then scrape the linked standings pages.\n",
    "    Each standings page is saved locally if not already present.\n",
    "    \"\"\"\n",
    "    main_url = f\"https://www.basketball-reference.com/leagues/NBA_{season_year}_games.html\"\n",
    "    initial_html = await fetch_html(main_url, \"#content .filter\")\n",
    "\n",
    "    doc = BeautifulSoup(initial_html, 'html.parser')\n",
    "    all_links = doc.find_all(\"a\")\n",
    "    href_values = [link.get(\"href\") for link in all_links if link.get(\"href\")]\n",
    "    standings_links = [f\"https://basketball-reference.com{href}\" for href in href_values]\n",
    "\n",
    "    for standings_url in standings_links:\n",
    "        filename = standings_url.split(\"/\")[-1]\n",
    "        output_file = os.path.join(STANDINGS_PATH, filename)\n",
    "        \n",
    "        if os.path.exists(output_file):\n",
    "            continue\n",
    "        \n",
    "        standings_html = await fetch_html(standings_url, \"#all_schedule\")\n",
    "        if standings_html is None:\n",
    "            continue\n",
    "        with open(output_file, \"w+\", encoding=\"utf-8\") as outfile:\n",
    "            outfile.write(standings_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37e08877-3e60-4c65-850d-aa3ad6d54387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-10 NBA Schedule | Basketball-Reference.com\n",
      "2010-11 NBA Schedule | Basketball-Reference.com\n",
      "2011-12 NBA Schedule | Basketball-Reference.com\n",
      "2012-13 NBA Schedule | Basketball-Reference.com\n",
      "2013-14 NBA Schedule | Basketball-Reference.com\n",
      "2014-15 NBA Schedule | Basketball-Reference.com\n",
      "2015-16 NBA Schedule | Basketball-Reference.com\n",
      "2016-17 NBA Schedule | Basketball-Reference.com\n",
      "2017-18 NBA Schedule | Basketball-Reference.com\n",
      "2018-19 NBA Schedule | Basketball-Reference.com\n",
      "2019-20 NBA Schedule | Basketball-Reference.com\n",
      "2020-21 NBA Schedule | Basketball-Reference.com\n",
      "2021-22 NBA Schedule | Basketball-Reference.com\n",
      "2022-23 NBA Schedule | Basketball-Reference.com\n"
     ]
    }
   ],
   "source": [
    "# Scrape data for all defined seasons\n",
    "for yr in YEARS:\n",
    "    await retrieve_season_data(yr)\n",
    "\n",
    "collected_files = os.listdir(STANDINGS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ffe6b69-1516-4e79-80e6-6cee8d770d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def extract_game_data(standings_filepath):\n",
    "    \"\"\"\n",
    "    Given a local standings file, parse it to find all box score links.\n",
    "    Download each box score HTML page and store it locally if not already present.\n",
    "    \"\"\"\n",
    "    with open(standings_filepath, 'r', encoding=\"utf-8\") as file_obj:\n",
    "        content = file_obj.read()\n",
    "\n",
    "    doc = BeautifulSoup(content, 'html.parser')\n",
    "    links_in_doc = doc.find_all(\"a\")\n",
    "    extracted_hrefs = [link.get(\"href\") for link in links_in_doc]\n",
    "    game_links = [href for href in extracted_hrefs if href and \"boxscore\" in href and href.endswith(\".html\")]\n",
    "    full_game_urls = [f\"https://www.basketball-reference.com{url}\" for url in game_links]\n",
    "\n",
    "    for game_url in full_game_urls:\n",
    "        local_filename = game_url.split(\"/\")[-1]\n",
    "        local_path = os.path.join(SCORES_PATH, local_filename)\n",
    "\n",
    "        if os.path.exists(local_path):\n",
    "            continue\n",
    "        \n",
    "        game_html = await fetch_html(game_url, \"#content\")\n",
    "        if game_html is None:\n",
    "            continue\n",
    "        with open(local_path, \"w+\", encoding=\"utf-8\") as score_file:\n",
    "            score_file.write(game_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3417ff27-1f51-4832-9ccf-754a1f9c8ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pistons vs Grizzlies, October 28, 2009 | Basketball-Reference.com\n",
      "Suns vs Clippers, October 28, 2009 | Basketball-Reference.com\n",
      "Rockets vs Warriors, October 28, 2009 | Basketball-Reference.com\n",
      "Jazz vs Nuggets, October 28, 2009 | Basketball-Reference.com\n",
      "Spurs vs Bulls, October 29, 2009 | Basketball-Reference.com\n",
      "Nuggets vs Trail Blazers, October 29, 2009 | Basketball-Reference.com\n",
      "Knicks vs Bobcats, October 30, 2009 | Basketball-Reference.com\n",
      "Bucks vs 76ers, October 30, 2009 | Basketball-Reference.com\n",
      "Wizards vs Hawks, October 30, 2009 | Basketball-Reference.com\n",
      "Bulls vs Celtics, October 30, 2009 | Basketball-Reference.com\n",
      "Kings vs Hornets, October 30, 2009 | Basketball-Reference.com\n",
      "Magic vs Nets, October 30, 2009 | Basketball-Reference.com\n",
      "Cavaliers vs Timberwolves, October 30, 2009 | Basketball-Reference.com\n",
      "Raptors vs Grizzlies, October 30, 2009 | Basketball-Reference.com\n",
      "Heat vs Pacers, October 30, 2009 | Basketball-Reference.com\n",
      "Thunder vs Pistons, October 30, 2009 | Basketball-Reference.com\n",
      "Clippers vs Jazz, October 30, 2009 | Basketball-Reference.com\n",
      "Warriors vs Suns, October 30, 2009 | Basketball-Reference.com\n",
      "Mavericks vs Lakers, October 30, 2009 | Basketball-Reference.com\n",
      "Nets vs Wizards, October 31, 2009 | Basketball-Reference.com\n",
      "Bobcats vs Cavaliers, October 31, 2009 | Basketball-Reference.com\n",
      "76ers vs Knicks, October 31, 2009 | Basketball-Reference.com\n",
      "Trail Blazers vs Rockets, October 31, 2009 | Basketball-Reference.com\n",
      "Pistons vs Bucks, October 31, 2009 | Basketball-Reference.com\n",
      "Kings vs Spurs, October 31, 2009 | Basketball-Reference.com\n",
      "Mavericks vs Clippers, October 31, 2009 | Basketball-Reference.com\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m standings_f \u001b[38;5;129;01min\u001b[39;00m season_related_files:\n\u001b[1;32m      5\u001b[0m     full_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(STANDINGS_PATH, standings_f)\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m extract_game_data(full_path)\n",
      "Cell \u001b[0;32mIn[5], line 22\u001b[0m, in \u001b[0;36mextract_game_data\u001b[0;34m(standings_filepath)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(local_path):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m game_html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m fetch_html(game_url, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#content\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m game_html \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m, in \u001b[0;36mfetch_html\u001b[0;34m(page_url, css_selector, delay_between_retries, max_attempts)\u001b[0m\n\u001b[1;32m      8\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(delay_between_retries \u001b[38;5;241m*\u001b[39m attempt)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m async_playwright() \u001b[38;5;28;01mas\u001b[39;00m playwright:\n\u001b[1;32m     11\u001b[0m         browser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m playwright\u001b[38;5;241m.\u001b[39mfirefox\u001b[38;5;241m.\u001b[39mlaunch()\n\u001b[1;32m     12\u001b[0m         page \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m browser\u001b[38;5;241m.\u001b[39mnew_page()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/playwright/async_api/_context_manager.py:40\u001b[0m, in \u001b[0;36mPlaywrightContextManager.__aenter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m loop\u001b[38;5;241m.\u001b[39mcreate_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mrun())\n\u001b[1;32m     38\u001b[0m playwright_future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mplaywright_future\n\u001b[0;32m---> 40\u001b[0m done, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mwait(\n\u001b[1;32m     41\u001b[0m     {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mon_error_future, playwright_future},\n\u001b[1;32m     42\u001b[0m     return_when\u001b[38;5;241m=\u001b[39masyncio\u001b[38;5;241m.\u001b[39mFIRST_COMPLETED,\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m playwright_future\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     45\u001b[0m     playwright_future\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/asyncio/tasks.py:464\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing coroutines is forbidden, use tasks explicitly.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    463\u001b[0m loop \u001b[38;5;241m=\u001b[39m events\u001b[38;5;241m.\u001b[39mget_running_loop()\n\u001b[0;32m--> 464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _wait(fs, timeout, return_when, loop)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/asyncio/tasks.py:550\u001b[0m, in \u001b[0;36m_wait\u001b[0;34m(fs, timeout, return_when, loop)\u001b[0m\n\u001b[1;32m    547\u001b[0m     f\u001b[38;5;241m.\u001b[39madd_done_callback(_on_completion)\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m waiter\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# For each season, find the corresponding standings files and extract their game data\n",
    "for yr in YEARS:\n",
    "    season_related_files = [f for f in collected_files if str(yr) in f]\n",
    "    for standings_f in season_related_files:\n",
    "        full_path = os.path.join(STANDINGS_PATH, standings_f)\n",
    "        await extract_game_data(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f0a99f-8841-4728-96a3-cd8645373367",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The error message above is showing because I interrupted the kernel.\n",
    "I did this because the full output with all scraped files would be too much to display.\n",
    "I have ran this program completey before in order to parse the data and use ml to predict.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
